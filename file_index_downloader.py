"""
Canvas å®Œæ•´æ–‡ä»¶ç´¢å¼•ä¸‹è½½å™¨

è‡ªåŠ¨ä¸‹è½½æ‰€æœ‰è¯¾ç¨‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ŒæŒ‰è¯¾ç¨‹å’Œæ¨¡å—ç»„ç»‡æ–‡ä»¶å¤¹ç»“æ„
å¹¶ä¸Šä¼ åˆ° OpenAI Vector Store
"""

import os
import sys
import asyncio
import aiohttp
from pathlib import Path
from datetime import datetime
import json
import time

from dotenv import load_dotenv
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, BarColumn, DownloadColumn, TransferSpeedColumn, TimeElapsedColumn
from rich.table import Table
from rich.panel import Panel
from rich.tree import Tree

try:
    from openai import OpenAI
    import openai
    OPENAI_VERSION = openai.__version__
except ImportError:
    OpenAI = None
    OPENAI_VERSION = None

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

console = Console()

# ä¸‹è½½æ ¹ç›®å½• - ä¿å­˜åˆ°é¡¹ç›®æ ¹ç›®å½•çš„ file_index æ–‡ä»¶å¤¹
# è„šæœ¬åœ¨ agent_framework-main/ ä¸‹ï¼Œéœ€è¦å‘ä¸Šä¸€çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
DOWNLOAD_ROOT = Path(__file__).parent.parent / "file_index"

# ä¸‹è½½ç»Ÿè®¡
stats = {
    "courses": 0,
    "modules": 0,
    "files_total": 0,
    "files_downloaded": 0,
    "files_skipped": 0,
    "files_failed": 0,
    "files_inaccessible": 0,
    "total_size": 0,
    "vector_stores_created": 0,
    "vector_stores_reused": 0,
    "files_uploaded_to_vector_store": 0,
    "files_upload_skipped": 0,
    "files_upload_failed": 0,
    "inaccessible_files": [],  # è®°å½•æ— æ³•è®¿é—®çš„æ–‡ä»¶
    "errors": []
}

# Vector Store é…ç½®
SUPPORTED_EXTENSIONS = {'.pdf', '.txt', '.md', '.doc', '.docx', '.ppt', '.pptx', '.xls', '.xlsx', '.json', '.csv'}
MAX_FILE_SIZE = 512 * 1024 * 1024  # 512 MB (OpenAI limit)


def sanitize_filename(name: str) -> str:
    """æ¸…ç†æ–‡ä»¶å/æ–‡ä»¶å¤¹åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    # Windowsä¸å…è®¸çš„å­—ç¬¦
    illegal_chars = '<>:"/\\|?*'
    for char in illegal_chars:
        name = name.replace(char, '_')
    # ç§»é™¤å‰åç©ºæ ¼å’Œç‚¹
    name = name.strip('. ')
    # é™åˆ¶é•¿åº¦
    if len(name) > 200:
        name = name[:200]
    return name or "unnamed"


async def fetch_all_pages(session, url, headers, params=None):
    """è·å–æ‰€æœ‰åˆ†é¡µæ•°æ®"""
    all_data = []
    current_url = url
    
    while current_url:
        try:
            async with session.get(current_url, headers=headers, params=params) as response:
                if response.status == 200:
                    data = await response.json()
                    if isinstance(data, list):
                        all_data.extend(data)
                    else:
                        all_data.append(data)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                    link_header = response.headers.get('Link', '')
                    current_url = None
                    if link_header:
                        for link in link_header.split(','):
                            if 'rel="next"' in link:
                                current_url = link[link.find('<')+1:link.find('>')]
                                break
                    params = None  # åç»­è¯·æ±‚ä¸éœ€è¦params
                else:
                    console.print(f"âš ï¸  è¯·æ±‚å¤±è´¥ ({response.status}): {current_url}", style="yellow")
                    break
                    
        except Exception as e:
            console.print(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}", style="red")
            break
    
    return all_data


async def download_file(session, file_info, file_path, course_name=""):
    """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
    file_url = file_info.get('url')
    file_name = file_info.get('display_name', 'unnamed')
    file_size = file_info.get('size', 0)
    file_id = file_info.get('id', '')
    
    if not file_url:
        return False, "æ— ä¸‹è½½é“¾æ¥"
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åŒ¹é…ï¼Œè·³è¿‡
    if file_path.exists() and file_path.stat().st_size == file_size:
        stats["files_skipped"] += 1
        return True, "å·²å­˜åœ¨"
    
    try:
        async with session.get(file_url) as response:
            if response.status == 200:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                file_path.parent.mkdir(parents=True, exist_ok=True)
                
                # ä¸‹è½½æ–‡ä»¶
                with open(file_path, 'wb') as f:
                    async for chunk in response.content.iter_chunked(8192):
                        f.write(chunk)
                
                stats["files_downloaded"] += 1
                stats["total_size"] += file_size
                return True, "æˆåŠŸ"
            elif response.status == 403:
                # è®°å½•æ— æ³•è®¿é—®çš„æ–‡ä»¶
                stats["files_inaccessible"] += 1
                stats["inaccessible_files"].append({
                    "course": course_name,
                    "file_name": file_name,
                    "file_id": file_id,
                    "error": "403 Forbidden"
                })
                return False, "403 Forbidden (æ— æƒè®¿é—®)"
            else:
                return False, f"HTTP {response.status}"
                
    except Exception as e:
        return False, str(e)


async def get_courses(session, canvas_url, headers):
    """è·å–æ‰€æœ‰è¯¾ç¨‹"""
    console.print("\nğŸ“š è·å–è¯¾ç¨‹åˆ—è¡¨...", style="cyan bold")
    
    courses = await fetch_all_pages(
        session,
        f"{canvas_url}/api/v1/courses",
        headers,
        params={"enrollment_state": "active", "per_page": 100}
    )
    
    console.print(f"âœ“ æ‰¾åˆ° {len(courses)} ä¸ªè¯¾ç¨‹\n", style="green")
    return courses


async def get_course_modules(session, canvas_url, headers, course_id):
    """è·å–è¯¾ç¨‹çš„æ‰€æœ‰æ¨¡å—"""
    modules = await fetch_all_pages(
        session,
        f"{canvas_url}/api/v1/courses/{course_id}/modules",
        headers,
        params={"include[]": "items", "per_page": 100}
    )
    return modules


async def get_module_items(session, canvas_url, headers, course_id, module_id):
    """è·å–æ¨¡å—çš„æ‰€æœ‰é¡¹ç›®"""
    items = await fetch_all_pages(
        session,
        f"{canvas_url}/api/v1/courses/{course_id}/modules/{module_id}/items",
        headers,
        params={"per_page": 100}
    )
    return items


async def get_course_files(session, canvas_url, headers, course_id):
    """è·å–è¯¾ç¨‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆFilesåŒºåŸŸï¼‰"""
    try:
        # å°è¯•ç›´æ¥è·å–æ–‡ä»¶åˆ—è¡¨
        async with session.get(
            f"{canvas_url}/api/v1/courses/{course_id}/files",
            headers=headers,
            params={"per_page": 1}
        ) as response:
            if response.status == 403:
                # 403 Forbidden - è®°å½•å¹¶è¿”å›ç©ºåˆ—è¡¨
                return None  # è¿”å› None è¡¨ç¤ºæ— æƒè®¿é—®
            elif response.status != 200:
                return []
        
        files = await fetch_all_pages(
            session,
            f"{canvas_url}/api/v1/courses/{course_id}/files",
            headers,
            params={"per_page": 100}
        )
        return files
    except:
        # å¦‚æœç›´æ¥è·å–å¤±è´¥ï¼Œå°è¯•é€šè¿‡æ–‡ä»¶å¤¹æ–¹å¼
        try:
            folders = await fetch_all_pages(
                session,
                f"{canvas_url}/api/v1/courses/{course_id}/folders",
                headers,
                params={"per_page": 100}
            )
            
            all_files = []
            for folder in folders:
                folder_files = await fetch_all_pages(
                    session,
                    f"{canvas_url}/api/v1/folders/{folder['id']}/files",
                    headers,
                    params={"per_page": 100}
                )
                all_files.extend(folder_files)
            
            return all_files
        except:
            return []


async def get_file_info(session, canvas_url, headers, file_id):
    """è·å–æ–‡ä»¶è¯¦ç»†ä¿¡æ¯"""
    try:
        async with session.get(
            f"{canvas_url}/api/v1/files/{file_id}",
            headers=headers
        ) as response:
            if response.status == 200:
                return await response.json()
    except:
        pass
    return None


async def get_page_content(session, canvas_url, headers, course_id, page_url):
    """è·å–é¡µé¢å†…å®¹"""
    try:
        async with session.get(
            f"{canvas_url}/api/v1/courses/{course_id}/pages/{page_url}",
            headers=headers
        ) as response:
            if response.status == 200:
                return await response.json()
    except:
        pass
    return None


async def get_assignment_details(session, canvas_url, headers, course_id, assignment_id):
    """è·å–ä½œä¸šè¯¦ç»†ä¿¡æ¯"""
    try:
        async with session.get(
            f"{canvas_url}/api/v1/courses/{course_id}/assignments/{assignment_id}",
            headers=headers
        ) as response:
            if response.status == 200:
                return await response.json()
    except:
        pass
    return None


def extract_files_from_html(html_content):
    """ä»HTMLå†…å®¹ä¸­æå–æ–‡ä»¶é“¾æ¥"""
    import re
    if not html_content:
        return []
    
    # åŒ¹é… Canvas æ–‡ä»¶é“¾æ¥
    # æ ¼å¼: /files/{file_id}/download æˆ– /courses/{course_id}/files/{file_id}
    pattern = r'/files/(\d+)(?:/download)?'
    matches = re.findall(pattern, html_content)
    
    return list(set(matches))  # å»é‡


def can_upload_to_vector_store(file_path: Path) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯ä»¥ä¸Šä¼ åˆ° Vector Store"""
    # æ£€æŸ¥æ‰©å±•å
    if file_path.suffix.lower() not in SUPPORTED_EXTENSIONS:
        return False
    
    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    try:
        if file_path.stat().st_size > MAX_FILE_SIZE:
            return False
    except:
        return False
    
    return True


def upload_to_vector_store(client, vector_store_id, file_path, course_name):
    """ä¸Šä¼ æ–‡ä»¶åˆ° Vector Store"""
    try:
        with open(file_path, 'rb') as f:
            file_response = client.files.create(
                file=f,
                purpose='assistants'
            )
        
        # å°†æ–‡ä»¶æ·»åŠ åˆ° Vector Storeï¼ˆä¸æ˜¯ beta APIï¼‰
        client.vector_stores.files.create(
            vector_store_id=vector_store_id,
            file_id=file_response.id
        )
        
        stats["files_uploaded_to_vector_store"] += 1
        return True, file_response.id
        
    except Exception as e:
        stats["files_upload_failed"] += 1
        stats["errors"].append({
            "course": course_name,
            "file": file_path.name,
            "error": f"Vector Storeä¸Šä¼ å¤±è´¥: {str(e)}"
        })
        return False, str(e)


def create_vector_store_for_course(client, course_name, course_code):
    """ä¸ºè¯¾ç¨‹åˆ›å»º Vector Store"""
    try:
        vector_store_name = f"{course_code}_{course_name}" if course_code else course_name
        
        # ä½¿ç”¨æ­£ç¡®çš„ API è·¯å¾„ï¼ˆä¸æ˜¯ betaï¼‰
        vector_store = client.vector_stores.create(
            name=vector_store_name[:100]  # é™åˆ¶é•¿åº¦
        )
        
        stats["vector_stores_created"] += 1
        return vector_store.id
        
    except AttributeError as e:
        console.print(f"âŒ Vector Stores API ä¸å¯ç”¨: {e}", style="red")
        console.print("   è¯·æ›´æ–° OpenAI åº“: pip install --upgrade openai", style="yellow")
        return None
    except Exception as e:
        console.print(f"âŒ åˆ›å»º Vector Store å¤±è´¥: {e}", style="red")
        import traceback
        console.print(traceback.format_exc(), style="red dim")
        return None


async def process_course(session, canvas_url, headers, course, progress, task_id):
    """å¤„ç†å•ä¸ªè¯¾ç¨‹"""
    course_id = course['id']
    course_name = sanitize_filename(course.get('name', f'Course_{course_id}'))
    course_code = course.get('course_code', '')
    
    # åˆ›å»ºè¯¾ç¨‹æ–‡ä»¶å¤¹
    course_path = DOWNLOAD_ROOT / f"{course_code}_{course_name}" if course_code else DOWNLOAD_ROOT / course_name
    course_path.mkdir(parents=True, exist_ok=True)
    
    progress.update(task_id, description=f"[cyan]å¤„ç†è¯¾ç¨‹: {course_name}")
    
    course_stats = {
        "modules": 0,
        "files_from_modules": 0,
        "files_from_files": 0,
        "files_downloaded": 0,
        "files_failed": 0
    }
    
    # ================================================
    # 1. å¤„ç† Modules ä¸­çš„æ–‡ä»¶
    # ================================================
    modules = await get_course_modules(session, canvas_url, headers, course_id)
    
    for module in modules:
        module_name = sanitize_filename(module.get('name', f'Module_{module["id"]}'))
        module_path = course_path / "Modules" / module_name
        
        course_stats["modules"] += 1
        
        # è·å–æ¨¡å—é¡¹ç›®
        items = module.get('items', [])
        if not items:
            items = await get_module_items(session, canvas_url, headers, course_id, module['id'])
        
        # å¤„ç†æ¨¡å—ä¸­çš„å„ç§ç±»å‹é¡¹ç›®
        for item in items:
            item_type = item.get('type')
            item_title = item.get('title', 'unnamed')
            
            # 1. å¤„ç† File ç±»å‹
            if item_type == 'File':
                file_id = item.get('content_id')
                if file_id:
                    file_info = await get_file_info(session, canvas_url, headers, file_id)
                    if file_info:
                        file_name = sanitize_filename(file_info.get('display_name', 'unnamed'))
                        file_path = module_path / file_name
                        
                        success, msg = await download_file(session, file_info, file_path, course_name)
                        
                        if success:
                            course_stats["files_from_modules"] += 1
                            course_stats["files_downloaded"] += 1
                        else:
                            course_stats["files_failed"] += 1
                            stats["errors"].append({
                                "course": course_name,
                                "module": module_name,
                                "file": file_name,
                                "error": msg
                            })
                    else:
                        stats["errors"].append({
                            "course": course_name,
                            "module": module_name,
                            "file": f"File ID {file_id}",
                            "error": "æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆå¯èƒ½æ— æƒé™ï¼‰"
                        })
            
            # 2. å¤„ç† Page ç±»å‹ï¼ˆè¯¾ç¨‹é¡µé¢å¯èƒ½åŒ…å«é™„ä»¶ï¼‰
            elif item_type == 'Page':
                page_url = item.get('page_url')
                if page_url:
                    page_content = await get_page_content(session, canvas_url, headers, course_id, page_url)
                    if page_content:
                        # ä¿å­˜é¡µé¢ HTML å†…å®¹
                        html_content = page_content.get('body', '')
                        if html_content:
                            page_file_name = sanitize_filename(f"{item_title}.html")
                            page_file_path = module_path / page_file_name
                            page_file_path.parent.mkdir(parents=True, exist_ok=True)
                            
                            with open(page_file_path, 'w', encoding='utf-8') as f:
                                f.write(html_content)
                            
                            course_stats["files_from_modules"] += 1
                            course_stats["files_downloaded"] += 1
                            stats["files_downloaded"] += 1
                        
                        # æå–é¡µé¢ä¸­çš„æ–‡ä»¶é“¾æ¥å¹¶ä¸‹è½½
                        file_ids = extract_files_from_html(html_content)
                        for file_id in file_ids:
                            file_info = await get_file_info(session, canvas_url, headers, file_id)
                            if file_info:
                                file_name = sanitize_filename(file_info.get('display_name', 'unnamed'))
                                file_path = module_path / file_name
                                
                                success, msg = await download_file(session, file_info, file_path, course_name)
                                if success:
                                    course_stats["files_from_modules"] += 1
                                    course_stats["files_downloaded"] += 1
            
            # 3. å¤„ç† Assignment ç±»å‹ï¼ˆä½œä¸šå¯èƒ½æœ‰é™„ä»¶ï¼‰
            elif item_type == 'Assignment':
                assignment_id = item.get('content_id')
                if assignment_id:
                    assignment_details = await get_assignment_details(
                        session, canvas_url, headers, course_id, assignment_id
                    )
                    if assignment_details:
                        # ä¿å­˜ä½œä¸šæè¿°ä¸º HTML
                        description = assignment_details.get('description', '')
                        if description:
                            assignment_file_name = sanitize_filename(f"{item_title}_description.html")
                            assignment_file_path = module_path / assignment_file_name
                            assignment_file_path.parent.mkdir(parents=True, exist_ok=True)
                            
                            with open(assignment_file_path, 'w', encoding='utf-8') as f:
                                f.write(description)
                            
                            course_stats["files_from_modules"] += 1
                            course_stats["files_downloaded"] += 1
                            stats["files_downloaded"] += 1
                        
                        # å¤„ç†ä½œä¸šçš„é™„ä»¶ï¼ˆattachmentså­—æ®µï¼‰
                        attachments = assignment_details.get('attachments', [])
                        for attachment in attachments:
                            # é™„ä»¶å°±æ˜¯ä¸€ä¸ªæ–‡ä»¶å¯¹è±¡
                            file_name = sanitize_filename(attachment.get('display_name', attachment.get('filename', 'unnamed')))
                            file_path = module_path / file_name
                            
                            success, msg = await download_file(session, attachment, file_path, course_name)
                            if success:
                                course_stats["files_from_modules"] += 1
                                course_stats["files_downloaded"] += 1
                            else:
                                course_stats["files_failed"] += 1
                                stats["errors"].append({
                                    "course": course_name,
                                    "module": module_name,
                                    "file": file_name,
                                    "error": f"é™„ä»¶ä¸‹è½½å¤±è´¥: {msg}"
                                })
                        
                        # æå–æè¿°ä¸­çš„æ–‡ä»¶é“¾æ¥
                        file_ids = extract_files_from_html(description)
                        for file_id in file_ids:
                            file_info = await get_file_info(session, canvas_url, headers, file_id)
                            if file_info:
                                file_name = sanitize_filename(file_info.get('display_name', 'unnamed'))
                                file_path = module_path / file_name
                                
                                success, msg = await download_file(session, file_info, file_path, course_name)
                                if success:
                                    course_stats["files_from_modules"] += 1
                                    course_stats["files_downloaded"] += 1
    
    # ================================================
    # 2. å¤„ç† Files åŒºåŸŸçš„æ–‡ä»¶
    # ================================================
    files = await get_course_files(session, canvas_url, headers, course_id)
    
    # å¦‚æœè¿”å› Noneï¼Œè¡¨ç¤ºæ•´ä¸ªè¯¾ç¨‹æ— æƒè®¿é—®ï¼ˆæå°‘è§ï¼‰
    if files is None:
        console.print(f"âš ï¸  è¯¾ç¨‹ '{course_name}' (ID: {course_id}) æ— æƒè®¿é—® (403 Forbidden)", style="yellow")
        return course_stats
    
    for file_info in files:
        file_name = sanitize_filename(file_info.get('display_name', 'unnamed'))
        # å°†FilesåŒºåŸŸçš„æ–‡ä»¶æ”¾åœ¨å•ç‹¬çš„æ–‡ä»¶å¤¹ä¸­
        file_path = course_path / "Files" / file_name
        
        success, msg = await download_file(session, file_info, file_path, course_name)
        
        if success:
            course_stats["files_from_files"] += 1
            course_stats["files_downloaded"] += 1
        else:
            course_stats["files_failed"] += 1
            stats["errors"].append({
                "course": course_name,
                "file": file_name,
                "error": msg
            })
    
    stats["courses"] += 1
    stats["modules"] += course_stats["modules"]
    stats["files_total"] += course_stats["files_from_modules"] + course_stats["files_from_files"]
    stats["files_failed"] += course_stats["files_failed"]
    
    return course_stats


async def main(skip_download=False, course_id=None, auto_confirm=False):
    """ä¸»å‡½æ•°
    
    Args:
        skip_download: å¦‚æœä¸ºTrueï¼Œè·³è¿‡ä¸‹è½½ç›´æ¥ä¸Šä¼ å·²æœ‰æ–‡ä»¶åˆ°Vector Store
        course_id: å¦‚æœæŒ‡å®šï¼Œåªä¸‹è½½è¯¥è¯¾ç¨‹IDçš„æ–‡ä»¶
        auto_confirm: å¦‚æœä¸ºTrueï¼Œè‡ªåŠ¨ç¡®è®¤ä¸‹è½½ï¼Œä¸è¯¢é—®ç”¨æˆ·
    """
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    console.print("\n" + "="*70, style="cyan bold")
    if skip_download:
        console.print("â˜ï¸  Canvas æ–‡ä»¶ä¸Šä¼ åˆ° Vector Store", style="cyan bold")
    else:
        console.print("ğŸ“¦ Canvas å®Œæ•´æ–‡ä»¶ç´¢å¼•ä¸‹è½½å™¨ + Vector Store ä¸Šä¼ ", style="cyan bold")
    console.print("="*70 + "\n", style="cyan bold")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    canvas_url = os.getenv("CANVAS_URL")
    canvas_token = os.getenv("CANVAS_ACCESS_TOKEN")
    openai_api_key = os.getenv("OPENAI_API_KEY")
    
    if not canvas_url or not canvas_token:
        console.print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° Canvas é…ç½®", style="red bold")
        console.print("è¯·ç¡®ä¿ .env æ–‡ä»¶åŒ…å«ï¼š", style="yellow")
        console.print("  - CANVAS_URL", style="yellow")
        console.print("  - CANVAS_ACCESS_TOKEN", style="yellow")
        return
    
    console.print(f"âœ“ Canvas URL: {canvas_url}", style="green")
    console.print(f"âœ“ Canvas Token å·²é…ç½®", style="green")
    console.print(f"âœ“ ä¸‹è½½ç›®å½•: {DOWNLOAD_ROOT.absolute()}", style="green")
    
    # æ£€æŸ¥ OpenAI é…ç½®
    upload_to_openai = False
    openai_client = None
    
    if openai_api_key:
        if OpenAI is None:
            console.print("âš ï¸  openai åº“æœªå®‰è£…ï¼Œå°†è·³è¿‡ Vector Store ä¸Šä¼ ", style="yellow")
            console.print("   å®‰è£…å‘½ä»¤: pip install 'openai>=1.20.0'", style="dim")
        else:
            try:
                # æ˜¾ç¤ºå½“å‰ç‰ˆæœ¬
                if OPENAI_VERSION:
                    console.print(f"âœ“ OpenAI åº“ç‰ˆæœ¬: {OPENAI_VERSION}", style="green")
                
                # åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼ˆéœ€è¦ assistants=v2 beta headerï¼‰
                openai_client = OpenAI(
                    api_key=openai_api_key,
                    default_headers={"OpenAI-Beta": "assistants=v2"}
                )
                
                console.print(f"âœ“ OpenAI API å·²é…ç½®", style="green")
                
                # å°è¯•éªŒè¯ Vector Stores APIï¼ˆé€šè¿‡å®é™…è°ƒç”¨æµ‹è¯•ï¼‰
                try:
                    # æµ‹è¯•æ˜¯å¦å¯ä»¥è®¿é—® vector_stores APIï¼ˆä¸æ˜¯ betaï¼ï¼‰
                    test_list = openai_client.vector_stores.list(limit=1)
                    console.print(f"âœ“ Vector Stores API å¯ç”¨", style="green")
                    upload_to_openai = True
                except AttributeError as ae:
                    console.print("âŒ Vector Stores API ä¸å¯ç”¨ (API ç»“æ„é—®é¢˜)", style="red")
                    console.print(f"   é”™è¯¯: {ae}", style="yellow")
                    console.print("   è¯·ç¡®è®¤ OpenAI åº“ç‰ˆæœ¬ >= 1.20.0", style="yellow")
                    openai_client = None
                except Exception as ve:
                    # API è°ƒç”¨å¤±è´¥ä½†ç»“æ„å­˜åœ¨ï¼Œå¯èƒ½æ˜¯æƒé™æˆ–å…¶ä»–é—®é¢˜
                    console.print(f"âš ï¸  Vector Stores API æµ‹è¯•å¤±è´¥: {ve}", style="yellow")
                    console.print("   å°†å°è¯•ç»§ç»­ä½¿ç”¨ï¼ˆå¯èƒ½åœ¨å®é™…ä¸Šä¼ æ—¶å·¥ä½œï¼‰", style="dim")
                    upload_to_openai = True
                    
            except Exception as e:
                console.print(f"âš ï¸  OpenAI åˆå§‹åŒ–å¤±è´¥: {e}", style="yellow")
                import traceback
                console.print(traceback.format_exc()[:500], style="red dim")
    else:
        console.print("âš ï¸  æœªé…ç½® OpenAI API Keyï¼Œå°†è·³è¿‡ Vector Store ä¸Šä¼ ", style="yellow")
        console.print("   éœ€è¦é…ç½®: OPENAI_API_KEY", style="dim")
    
    console.print()
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    DOWNLOAD_ROOT.mkdir(parents=True, exist_ok=True)
    
    # å¦‚æœåªä¸Šä¼ ï¼Œæ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if skip_download:
        if not DOWNLOAD_ROOT.exists() or not any(DOWNLOAD_ROOT.iterdir()):
            console.print("âŒ é”™è¯¯ï¼šfile_index æ–‡ä»¶å¤¹ä¸å­˜åœ¨æˆ–ä¸ºç©º", style="red bold")
            console.print(f"è¯·å…ˆè¿è¡Œä¸‹è½½å‘½ä»¤æˆ–ç¡®ä¿æ–‡ä»¶å·²å­˜åœ¨äº: {DOWNLOAD_ROOT.absolute()}", style="yellow")
            return
        
        console.print(f"âœ“ æ‰¾åˆ°ä¸‹è½½æ–‡ä»¶å¤¹: {DOWNLOAD_ROOT.absolute()}", style="green")
    
    start_time = datetime.now()
    
    # ================================================
    # ä¸‹è½½éƒ¨åˆ†ï¼ˆå¯é€‰ï¼‰
    # ================================================
    if not skip_download:
        headers = {
            "Authorization": f"Bearer {canvas_token}",
            "Accept": "application/json"
        }
        
        async with aiohttp.ClientSession() as session:
            # è·å–æ‰€æœ‰è¯¾ç¨‹
            all_courses = await get_courses(session, canvas_url, headers)
            
            if not all_courses:
                console.print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è¯¾ç¨‹", style="yellow")
                return
            
            # å¦‚æœæŒ‡å®šäº†è¯¾ç¨‹IDï¼Œåªå¤„ç†è¯¥è¯¾ç¨‹
            if course_id:
                courses = [c for c in all_courses if str(c['id']) == str(course_id)]
                if not courses:
                    console.print(f"âŒ æœªæ‰¾åˆ°è¯¾ç¨‹ID: {course_id}", style="red bold")
                    console.print("\nå¯ç”¨çš„è¯¾ç¨‹:", style="yellow")
                    for i, course in enumerate(all_courses, 1):
                        console.print(f"  {i}. {course.get('name', 'N/A')} (ID: {course['id']})", style="dim")
                    return
                console.print(f"âœ“ æ‰¾åˆ°æŒ‡å®šè¯¾ç¨‹: {courses[0].get('name', 'N/A')} (ID: {course_id})", style="green bold")
            else:
                courses = all_courses
                # æ˜¾ç¤ºè¯¾ç¨‹åˆ—è¡¨
                console.print("ğŸ“‹ è¯¾ç¨‹åˆ—è¡¨:", style="cyan bold")
                for i, course in enumerate(courses, 1):
                    console.print(f"  {i}. {course.get('name', 'N/A')} (ID: {course['id']})", style="dim")
                console.print()
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­ï¼ˆé™¤éæ˜¯è‡ªåŠ¨ç¡®è®¤æ¨¡å¼ï¼‰
                if not auto_confirm:
                    console.print(f"å°†ä¸‹è½½ {len(courses)} ä¸ªè¯¾ç¨‹çš„æ‰€æœ‰æ–‡ä»¶", style="yellow bold")
                    response = console.input("æ˜¯å¦ç»§ç»­? (y/n): ")
                    
                    if response.lower() != 'y':
                        console.print("å·²å–æ¶ˆ", style="yellow")
                        return
                else:
                    console.print(f"è‡ªåŠ¨æ¨¡å¼ï¼šæ£€æŸ¥ {len(courses)} ä¸ªè¯¾ç¨‹çš„æ–‡ä»¶ï¼ˆåªä¸‹è½½ç¼ºå¤±çš„æ–‡ä»¶ï¼‰", style="green bold")
            
            console.print()
            
            # å¼€å§‹ä¸‹è½½
            with Progress(
                SpinnerColumn(),
                *Progress.get_default_columns(),
                TimeElapsedColumn(),
                console=console
            ) as progress:
                main_task = progress.add_task(
                    "[cyan]æ€»ä½“è¿›åº¦",
                    total=len(courses)
                )
                
                for course in courses:
                    course_stats = await process_course(
                        session, canvas_url, headers, course, progress, main_task
                    )
                    
                    progress.update(main_task, advance=1)
    else:
        console.print("â© è·³è¿‡ä¸‹è½½ï¼Œç›´æ¥å¤„ç†å·²æœ‰æ–‡ä»¶\n", style="yellow")
    
    # ================================================
    # ä¸Šä¼ åˆ° OpenAI Vector Store
    # ================================================
    if upload_to_openai and openai_client:
        console.print("\n" + "="*70, style="magenta bold")
        console.print("â˜ï¸  ä¸Šä¼ æ–‡ä»¶åˆ° OpenAI Vector Store", style="magenta bold")
        console.print("="*70 + "\n", style="magenta bold")
        
        # è¯»å–ç°æœ‰çš„ vector_stores_mapping.jsonï¼Œè·å–å·²ä¸Šä¼ çš„æ–‡ä»¶
        existing_mapping = {}
        mapping_file = DOWNLOAD_ROOT / "vector_stores_mapping.json"
        if mapping_file.exists():
            with open(mapping_file, 'r', encoding='utf-8') as f:
                existing_mapping = json.load(f)
        
        # è·å–æ‰€æœ‰å·²ä¸‹è½½çš„æ–‡ä»¶å¹¶æŒ‰è¯¾ç¨‹ç»„ç»‡
        course_files = {}
        
        for course_folder in DOWNLOAD_ROOT.iterdir():
            if course_folder.is_dir() and not course_folder.name.startswith('.'):
                course_name = course_folder.name
                files_to_upload = []
                
                # è·å–è¯¥è¯¾ç¨‹å·²ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„ï¼ˆæ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦ï¼‰
                uploaded_files = set()
                if course_name in existing_mapping:
                    for file_info in existing_mapping[course_name].get('files', []):
                        file_path_in_mapping = file_info.get('path', '')
                        # æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦ä¸ºæ­£æ–œæ è¿›è¡Œæ¯”è¾ƒ
                        normalized_path = file_path_in_mapping.replace('\\', '/')
                        uploaded_files.add(normalized_path)
                
                # æ”¶é›†æ‰€æœ‰å¯ä¸Šä¼ çš„æ–‡ä»¶ï¼ˆè·³è¿‡å·²ä¸Šä¼ çš„ï¼‰
                for file_path in course_folder.rglob('*'):
                    if file_path.is_file() and can_upload_to_vector_store(file_path):
                        # è®¡ç®—ç›¸å¯¹è·¯å¾„å¹¶æ ‡å‡†åŒ–ä¸ºæ­£æ–œæ 
                        relative_path = str(file_path.relative_to(DOWNLOAD_ROOT)).replace('\\', '/')
                        # å¦‚æœæ–‡ä»¶è¿˜æ²¡ä¸Šä¼ ï¼Œæ·»åŠ åˆ°åˆ—è¡¨
                        if relative_path not in uploaded_files:
                            files_to_upload.append(file_path)
                        else:
                            stats["files_upload_skipped"] += 1
                
                if files_to_upload:
                    course_files[course_name] = files_to_upload
        
        total_new_files = sum(len(files) for files in course_files.values())
        
        if total_new_files > 0:
            console.print(f"æ‰¾åˆ° {len(course_files)} ä¸ªè¯¾ç¨‹ï¼Œå…± {total_new_files} ä¸ªæ–°æ–‡ä»¶éœ€è¦ä¸Šä¼ \n", style="green")
        else:
            console.print("âœ“ æ‰€æœ‰æ–‡ä»¶éƒ½å·²ä¸Šä¼ åˆ° Vector Store\n", style="green")
        
        if course_files:
            
            with Progress(
                SpinnerColumn(),
                *Progress.get_default_columns(),
                TimeElapsedColumn(),
                console=console
            ) as progress:
                upload_task = progress.add_task(
                    "[magenta]ä¸Šä¼ åˆ° Vector Store",
                    total=len(course_files)
                )
                
                # ä¿å­˜ Vector Store ä¿¡æ¯
                vector_stores_info = {}
                
                for course_name, files in course_files.items():
                    progress.update(upload_task, description=f"[magenta]å¤„ç†: {course_name[:40]}")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ Vector Storeï¼Œå¦‚æœæœ‰å°±ä½¿ç”¨ç°æœ‰çš„
                    if course_name in existing_mapping and 'vector_store_id' in existing_mapping[course_name]:
                        vector_store_id = existing_mapping[course_name]['vector_store_id']
                        console.print(f"  ä½¿ç”¨ç°æœ‰ Vector Store: {vector_store_id}", style="dim")
                        stats["vector_stores_reused"] += 1
                        
                        # ä¿ç•™ç°æœ‰çš„æ–‡ä»¶åˆ—è¡¨
                        vector_stores_info[course_name] = {
                            "vector_store_id": vector_store_id,
                            "files": existing_mapping[course_name].get('files', [])
                        }
                    else:
                        # ä¸ºæ¯ä¸ªè¯¾ç¨‹åˆ›å»ºä¸€ä¸ªæ–°çš„ Vector Store
                        vector_store_id = create_vector_store_for_course(openai_client, course_name, "")
                        
                        if vector_store_id:
                            vector_stores_info[course_name] = {
                                "vector_store_id": vector_store_id,
                                "files": []
                            }
                        else:
                            vector_store_id = None
                    
                    if vector_store_id:
                        # ä¸Šä¼ æ–°æ–‡ä»¶
                        for file_path in files:
                            success, file_id = upload_to_vector_store(
                                openai_client,
                                vector_store_id,
                                file_path,
                                course_name
                            )
                            
                            if success:
                                vector_stores_info[course_name]["files"].append({
                                    "path": str(file_path.relative_to(DOWNLOAD_ROOT)),
                                    "file_id": file_id
                                })
                            
                            # é¿å…é€Ÿç‡é™åˆ¶
                            await asyncio.sleep(0.1)
                    
                    progress.update(upload_task, advance=1)
                
                # åˆå¹¶ç°æœ‰çš„mappingï¼ˆä¿ç•™æ²¡æœ‰æ–°æ–‡ä»¶ä¸Šä¼ çš„è¯¾ç¨‹ï¼‰
                for course_name, course_data in existing_mapping.items():
                    if course_name not in vector_stores_info:
                        vector_stores_info[course_name] = course_data
                
                # ä¿å­˜ Vector Store æ˜ å°„
                vector_store_mapping_path = DOWNLOAD_ROOT / "vector_stores_mapping.json"
                with open(vector_store_mapping_path, 'w', encoding='utf-8') as f:
                    json.dump(vector_stores_info, f, indent=2, ensure_ascii=False)
                
                console.print(f"\nâœ“ Vector Store æ˜ å°„å·²ä¿å­˜: {vector_store_mapping_path}", style="green")
        elif existing_mapping:
            console.print("âœ“ æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦ä¸Šä¼ ï¼Œä¿æŒç°æœ‰ Vector Store é…ç½®", style="green")
        else:
            console.print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ä¸Šä¼ åˆ° Vector Store çš„æ–‡ä»¶", style="yellow")
    
    # å®Œæˆ
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    console.print("\n" + "="*70, style="green bold")
    console.print("âœ… åŒæ­¥å®Œæˆï¼", style="green bold")
    console.print("="*70 + "\n", style="green bold")
    
    # æ˜¾ç¤ºå®é™…æ“ä½œçš„æ–‡ä»¶æ•°
    actual_downloaded = stats["files_downloaded"]
    actual_skipped = stats["files_skipped"]
    console.print(f"ğŸ“Š å®é™…æ–°ä¸‹è½½: {actual_downloaded} ä¸ªæ–‡ä»¶", style="cyan")
    console.print(f"ğŸ“Š è·³è¿‡å·²å­˜åœ¨: {actual_skipped} ä¸ªæ–‡ä»¶", style="dim")
    
    # ç»Ÿè®¡è¡¨æ ¼
    table = Table(title="ä¸‹è½½ä¸ä¸Šä¼ ç»Ÿè®¡", show_header=True)
    table.add_column("é¡¹ç›®", style="cyan", width=30)
    table.add_column("æ•°é‡", style="green", justify="right", width=15)
    
    table.add_row("â”â”â”â” ä¸‹è½½ç»Ÿè®¡ â”â”â”â”", "", style="bold cyan")
    table.add_row("è¯¾ç¨‹æ€»æ•°", str(stats["courses"]))
    table.add_row("æ¨¡å—æ€»æ•°", str(stats["modules"]))
    table.add_row("æ–‡ä»¶æ€»æ•°", str(stats["files_total"]))
    table.add_row("æˆåŠŸä¸‹è½½", str(stats["files_downloaded"]))
    table.add_row("å·²è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰", str(stats["files_skipped"]))
    table.add_row("ä¸‹è½½å¤±è´¥", str(stats["files_failed"]))
    if stats["files_inaccessible"] > 0:
        table.add_row("æ— æ³•è®¿é—®ï¼ˆ403ï¼‰", str(stats["files_inaccessible"]), style="yellow")
    table.add_row("æ€»å¤§å°", f"{stats['total_size'] / (1024*1024):.2f} MB")
    
    if upload_to_openai:
        table.add_row("â”â”â”â” Vector Store â”â”â”â”", "", style="bold magenta")
        table.add_row("Vector Stores åˆ›å»º", str(stats["vector_stores_created"]))
        table.add_row("Vector Stores é‡ç”¨", str(stats["vector_stores_reused"]))
        table.add_row("æ–‡ä»¶ä¸Šä¼ æˆåŠŸ", str(stats["files_uploaded_to_vector_store"]))
        table.add_row("æ–‡ä»¶è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰", str(stats["files_upload_skipped"]), style="dim")
        table.add_row("æ–‡ä»¶ä¸Šä¼ å¤±è´¥", str(stats["files_upload_failed"]))
    
    table.add_row("â”â”â”â”â”â”â”â”â”â”â”â”", "", style="bold")
    table.add_row("æ€»ç”¨æ—¶", f"{duration:.1f} ç§’")
    
    console.print(table)
    console.print()
    
    # ä¿å­˜ä¸‹è½½æŠ¥å‘Š
    report = {
        "timestamp": datetime.now().isoformat(),
        "canvas_url": canvas_url,
        "statistics": stats,
        "duration_seconds": duration
    }
    
    report_path = DOWNLOAD_ROOT / "download_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    console.print(f"ğŸ“„ ä¸‹è½½æŠ¥å‘Šå·²ä¿å­˜: {report_path}", style="dim")
    
    # å¦‚æœæœ‰é”™è¯¯ï¼Œæ˜¾ç¤ºé”™è¯¯åˆ—è¡¨
    if stats["errors"]:
        console.print(f"\nâš ï¸  {len(stats['errors'])} ä¸ªæ–‡ä»¶ä¸‹è½½å¤±è´¥:", style="yellow bold")
        error_table = Table(show_header=True)
        error_table.add_column("è¯¾ç¨‹", style="cyan")
        error_table.add_column("æ–‡ä»¶", style="white")
        error_table.add_column("é”™è¯¯", style="red")
        
        for error in stats["errors"][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
            error_table.add_row(
                error.get("course", "N/A"),
                error.get("file", "N/A"),
                error.get("error", "N/A")[:50]
            )
        
        console.print(error_table)
        
        if len(stats["errors"]) > 20:
            console.print(f"\n... è¿˜æœ‰ {len(stats['errors']) - 20} ä¸ªé”™è¯¯æœªæ˜¾ç¤º", style="dim")
    
    console.print(f"\nğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®: {DOWNLOAD_ROOT.absolute()}", style="green bold")
    
    # ä¿å­˜æ— æ³•è®¿é—®çš„æ–‡ä»¶åˆ—è¡¨
    if stats["inaccessible_files"]:
        inaccessible_file = DOWNLOAD_ROOT / "inaccessible_files.json"
        with open(inaccessible_file, 'w', encoding='utf-8') as f:
            json.dump(stats["inaccessible_files"], f, indent=2, ensure_ascii=False)
        console.print(f"\nâš ï¸  {len(stats['inaccessible_files'])} ä¸ªæ–‡ä»¶æ— æ³•è®¿é—®ï¼ˆå·²è®°å½•åˆ° inaccessible_files.jsonï¼‰", style="yellow")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Canvas æ–‡ä»¶ä¸‹è½½å™¨å’Œ Vector Store ä¸Šä¼ å·¥å…·"
    )
    parser.add_argument(
        "--upload-only",
        action="store_true",
        help="åªä¸Šä¼ å·²ä¸‹è½½çš„æ–‡ä»¶åˆ° Vector Storeï¼Œè·³è¿‡ä¸‹è½½æ­¥éª¤"
    )
    parser.add_argument(
        "--skip-download",
        action="store_true",
        help="åŒ --upload-onlyï¼ˆåˆ«åï¼‰"
    )
    parser.add_argument(
        "--course-id",
        type=str,
        help="åªä¸‹è½½æŒ‡å®šè¯¾ç¨‹IDçš„æ–‡ä»¶ï¼ˆä¾‹å¦‚ï¼š--course-id 154630ï¼‰"
    )
    
    args = parser.parse_args()
    skip_download = args.upload_only or args.skip_download
    course_id = args.course_id
    
    try:
        asyncio.run(main(skip_download=skip_download, course_id=course_id))
    except KeyboardInterrupt:
        console.print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ", style="yellow")
        if stats['files_downloaded'] > 0:
            console.print(f"å·²ä¸‹è½½: {stats['files_downloaded']} ä¸ªæ–‡ä»¶", style="dim")
        if stats['files_uploaded_to_vector_store'] > 0:
            console.print(f"å·²ä¸Šä¼ : {stats['files_uploaded_to_vector_store']} ä¸ªæ–‡ä»¶", style="dim")
    except Exception as e:
        console.print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}", style="red bold")
        import traceback
        console.print(traceback.format_exc(), style="red dim")

